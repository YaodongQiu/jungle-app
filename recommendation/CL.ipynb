{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b7376a",
   "metadata": {},
   "source": [
    "import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e60ae04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e4fafe",
   "metadata": {},
   "source": [
    "Connect to database and extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c16d0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library to connect data base and preprocess data\n",
    "#import util\n",
    "DATABASE_ACCESS = \"mongodb+srv://yelshall:yyForever-53611@auth-test.p4buu.mongodb.net/db?retryWrites=true&w=majority\"\n",
    "\n",
    "## connect to the mongo database and return target table as mongo collection\n",
    "## load the database table into np array\n",
    "## take mongo db as arguement\n",
    "## return dataframe\n",
    "def load_data(db,table):\n",
    "    cluster = MongoClient(DATABASE_ACCESS)\n",
    "    return pd.DataFrame(list(cluster[db][table].find()))\n",
    "\n",
    "## return user data as dataframe\n",
    "def get_users():\n",
    "    return load_data(\"db\",\"students\")\n",
    "\n",
    "## return events data as dataframe\n",
    "def get_events():\n",
    "    return load_data(\"db\",\"events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ada9352",
   "metadata": {},
   "source": [
    "Utility Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d7b119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get events id as numpy array\n",
    "def get_events_id():\n",
    "    return np.array(get_events()[\"_id\"])\n",
    "\n",
    "## get  users id as numpy array\n",
    "def get_users_id(df):\n",
    "    return np.array(df[\"_id\"])\n",
    "## check if a events inside a diction's list\n",
    "\n",
    "def is_in_dict(obj_user,obj_events,D):\n",
    "    return D[obj_user].count(obj_events)==1\n",
    "\n",
    "## use the df to build dislike/like events dictionary\n",
    "def build_liked_dict(df):\n",
    "    return df.set_index(\"_id\").to_dict()[\"interestedEvents\"]\n",
    "\n",
    "## use the df to build dislike events dictionary\n",
    "def build_disliked_dict(df):\n",
    "    return df.set_index(\"_id\").to_dict()[\"unlikedEvents\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8e5c2453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [618c67afffafd43022036124, 618c67afffafd430220...\n",
       "1      [618c67acffafd4302203609f, 618c67acffafd430220...\n",
       "2      [618c67acffafd43022036097, 618c67acffafd430220...\n",
       "3      [618c67b0ffafd4302203614a, 618c67b1ffafd430220...\n",
       "4      [618c67acffafd4302203609f, 618c67acffafd430220...\n",
       "                             ...                        \n",
       "613    [618c67abffafd43022036072, 618c67abffafd430220...\n",
       "614    [618c67b2ffafd430220361a8, 618c67acffafd430220...\n",
       "615                                                   []\n",
       "616    [618c67aeffafd430220360f4, 618c67b0ffafd430220...\n",
       "617                                                   []\n",
       "Name: interestedEvents, Length: 618, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = df_train[\"interestedEvents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6660696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train = get_users()\n",
    "print(df_train.shape)\n",
    "liked_dict = build_liked_dict(df_train)\n",
    "disliked_dict = build_disliked_dict(df_train)\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for user in liked_dict:\n",
    "    for event in liked_dict[user]:\n",
    "        train_data.append([user,event,1])\n",
    "\n",
    "for user in disliked_dict:\n",
    "    for event in disliked_dict[user]:\n",
    "        train_data.append([user,event,0])\n",
    "\n",
    "\n",
    "train_data = pd.DataFrame(np.array(train_data),columns = [\"user_id\",\"event_id\",\"rating\"])\n",
    "users, unique_user_ids = pd.factorize(train_data['user_id'])\n",
    "events, unique_event_ids = pd.factorize(train_data['event_id'])\n",
    "ratings = train_data['rating'].values\n",
    "n_1_labels = np.sum(ratings)\n",
    "n_0_labels = ratings.shape[0] - n_1_labels\n",
    "ratings = ratings.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f608ddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616,)\n"
     ]
    }
   ],
   "source": [
    "print(unique_user_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "284d1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "## users and items here are \n",
    "class MatrixFactorization():\n",
    "    def __init__(self, n_users, n_events, n_factors): ## This will also take care of initilizing the weights\n",
    "        self.n_users = n_users\n",
    "        self.n_events = n_events\n",
    "        self.n_factors = n_factors\n",
    "        self.user_factors = torch.rand(n_users, n_factors, dtype=torch.float32,requires_grad=False)/n_factors\n",
    "        self.event_factors = torch.rand(n_events, n_factors, dtype=torch.float32,requires_grad=False)/n_factors\n",
    "\n",
    "## these 2 function compute the gradient regard to U and V\n",
    "## it uses MSE\n",
    "    def gradient_U(self, users, events, ratings, lambda_):\n",
    "        # users is a list of user ids\n",
    "        # events is a list of item ids\n",
    "        y_hat = torch.sigmoid((self.user_factors[users,:] * self.event_factors[events,:]).sum(dim=1))\n",
    "        # print(\"user_factors[users,:]\",self.user_factors[users,:])\n",
    "        # print(\"user_factors[1,2,3]: \", self.user_factors[[0,0,0],:])\n",
    "        # print(\"users\",users)\n",
    "        return ((lambda_*self.user_factors[users,:].T - self.event_factors[events,:].T * (ratings - y_hat) * (ratings*n_0_labels + (1-ratings)*n_1_labels)/(n_0_labels+n_1_labels)).T)\n",
    "\n",
    "    def gradient_V(self, users, events, ratings, lambda_):\n",
    "        # users is a list of user ids\n",
    "        # items is a list of item ids\n",
    "        y_hat = torch.sigmoid( (self.user_factors[users,:] * self.event_factors[events,:]).sum(dim=1) )\n",
    "        return ((lambda_*self.event_factors[events,:].T - self.user_factors[users,:].T * (ratings - y_hat) * (ratings*n_0_labels + (1-ratings)*n_1_labels)/(n_0_labels+n_1_labels)).T) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb784b6",
   "metadata": {},
   "source": [
    "test on gradient mf class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f18ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn training data into torch tensors\n",
    "torch_users = torch.tensor(users,dtype=torch.long)\n",
    "torch_events = torch.tensor(events,dtype=torch.long)\n",
    "torch_ratings = torch.tensor(ratings,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d759d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_users = 616 n_events = 77\n"
     ]
    }
   ],
   "source": [
    "n_users = len(unique_user_ids)\n",
    "n_events = len(unique_event_ids)\n",
    "print(f'n_users = {n_users} n_events = {n_events}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d56256c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -33748.0703125\n",
      "tensor([0.5117, 0.5117, 0.5109,  ..., 0.5161, 0.5093, 0.5187])\n",
      "Epoch 1 last Matthew's correlation coefficient 0.0\n",
      "y_hat [ True  True  True ...  True  True  True]\n",
      "rating [1. 1. 1. ... 0. 0. 0.]\n",
      "accuracy 0.2594560669456067\n",
      "Loss: -33475.81640625\n",
      "tensor([0.5041, 0.5047, 0.5040,  ..., 0.5066, 0.5016, 0.5055])\n",
      "Epoch 2001 last Matthew's correlation coefficient -0.0062001672664986065\n",
      "y_hat [ True  True  True ...  True  True  True]\n",
      "rating [1. 1. 1. ... 0. 0. 0.]\n",
      "accuracy 0.2631380753138075\n",
      "Loss: -33323.9453125\n",
      "tensor([0.5013, 0.5019, 0.5015,  ..., 0.5026, 0.4984, 0.5002])\n",
      "Epoch 4001 last Matthew's correlation coefficient -0.003595082074207757\n",
      "y_hat [ True  True  True ...  True False  True]\n",
      "rating [1. 1. 1. ... 0. 0. 0.]\n",
      "accuracy 0.29721757322175735\n",
      "Loss: -33242.66015625\n",
      "tensor([0.5002, 0.5007, 0.5004,  ..., 0.5009, 0.4970, 0.4979])\n",
      "Epoch 6001 last Matthew's correlation coefficient 0.003580553180268431\n",
      "y_hat [ True  True  True ...  True False False]\n",
      "rating [1. 1. 1. ... 0. 0. 0.]\n",
      "accuracy 0.3709623430962343\n",
      "Loss: -33199.55078125\n",
      "tensor([0.4996, 0.5000, 0.4999,  ..., 0.5001, 0.4963, 0.4969])\n",
      "Epoch 8001 last Matthew's correlation coefficient 0.001082250658485688\n",
      "y_hat [False False False ...  True False False]\n",
      "rating [1. 1. 1. ... 0. 0. 0.]\n",
      "accuracy 0.44569037656903765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "model = MatrixFactorization(n_users, n_events, n_factors=5)\n",
    "\n",
    "epochs = 10000\n",
    "learning_rate = 0.001\n",
    "lambda_ = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.user_factors[torch_users,:] -= learning_rate * model.gradient_U(torch_users,torch_events,torch_ratings,lambda_)\n",
    "    model.event_factors[torch_events,:] -= learning_rate * model.gradient_V(torch_users,torch_events,torch_ratings,lambda_)\n",
    "\n",
    "    if epoch % 2000 == 0:\n",
    "        with torch.no_grad():\n",
    "            y_hat = torch.sigmoid((model.user_factors[torch_users,:] * model.event_factors[torch_events,:]).sum(dim=1))\n",
    "            print(f'Loss: {(torch_ratings * torch.log(y_hat) + (1 - torch_ratings) * torch.log((1.-y_hat))).sum()}')\n",
    "            print(y_hat)\n",
    "            y_hat = y_hat.gt(0.5).numpy()\n",
    "            \n",
    "            print(f'Epoch {epoch+1} last Matthew\\'s correlation coefficient {matthews_corrcoef(y_hat,ratings)}', flush=True)\n",
    "            print(\"y_hat\",y_hat)\n",
    "            print(\"rating\",ratings)\n",
    "            print(\"accuracy\",accuracy_score(y_hat,ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51045076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19195"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_hat==True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4f1bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_factors = model.event_factors\n",
    "user_factors = model.user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f5712a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2465, -1.0289,  0.6850, -1.2479,  0.5317],\n",
       "        [ 0.2355, -0.9114,  0.6447, -1.3151,  0.6602],\n",
       "        [ 0.2317, -0.9624,  0.7140, -1.2971,  0.5197],\n",
       "        ...,\n",
       "        [ 0.4113,  1.7490, -1.2034,  1.7808,  0.2786],\n",
       "        [ 0.8162,  0.2718,  0.7131, -1.4473,  0.3165],\n",
       "        [ 0.3146,  2.5616, -0.8140,  0.9565,  0.9984]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e8076aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id = get_events_id()\n",
    "user_id = get_users_id(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b29d3e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaodongqiu/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (618) does not match length of index (616)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cb/8x28t211217d97zhd7j1bj900000gn/T/ipykernel_12178/2868775581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# ## user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_user_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"e1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"e2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"e3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"e4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"e5\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf_user_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mdict_user_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_user_factors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"record\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (618) does not match length of index (616)"
     ]
    }
   ],
   "source": [
    "## event \n",
    "df_event_factors = pd.DataFrame(np.array(event_factors),columns=[\"e1\",\"e2\",\"e3\",\"e4\",\"e5\"])\n",
    "df_event_factors[\"event_id\"] = event_id\n",
    "dict_event_factors = df_event_factors.to_dict(\"record\")\n",
    "\n",
    "# ## user\n",
    "df_user_factors = pd.DataFrame(np.array(user_factors),columns=[\"e1\",\"e2\",\"e3\",\"e4\",\"e5\"])\n",
    "df_user_factors[\"user_id\"] = user_id\n",
    "dict_user_factors = df_user_factors.to_dict(\"record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06c127",
   "metadata": {},
   "source": [
    "Save model to data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534cc758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaodongqiu/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: remove is deprecated. Use delete_one or delete_many instead.\n",
      "  \"\"\"\n",
      "/Users/yaodongqiu/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: remove is deprecated. Use delete_one or delete_many instead.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f8e28da51e0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATABASE_ACCESS = \"mongodb+srv://yelshall:yyForever-53611@auth-test.p4buu.mongodb.net/db?retryWrites=true&w=majority\"\n",
    "cluster = MongoClient(DATABASE_ACCESS)\n",
    "db_event_factors = cluster[\"db\"][\"event_factors\"]\n",
    "db_user_factors = cluster[\"db\"][\"user_factors\"]\n",
    "db_event_factors.remove({})\n",
    "db_user_factors.remove({})\n",
    "db_event_factors.insert_many(dict_event_factors)\n",
    "db_user_factors.insert_many(dict_user_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9cdad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
